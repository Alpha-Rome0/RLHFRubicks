{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbd3b53c28fb7674",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-26T14:49:52.643729Z",
     "start_time": "2024-04-26T14:48:58.234426Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import torch, csv, json\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "import bitsandbytes as bnb\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n",
    "from peft import LoraConfig\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T14:49:52.651672Z",
     "start_time": "2024-04-26T14:49:52.645227Z"
    }
   },
   "id": "14a2092c523f52c8"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def csv_to_jsonl(csv_path, jsonl_path):\n",
    "    with open('ttt_prompt.txt', 'r') as file:\n",
    "        # Read the entire file into a string\n",
    "        prompt = file.read()\n",
    "    with open(csv_path, 'r') as csv_file, open(jsonl_path, 'w') as jsonl_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        for row in reader:\n",
    "            jsonl_file.write(\n",
    "                json.dumps({\"prompt\": prompt.format(state = row[\"Game States\"]), \"completion\": f'{row[\"Optimal Moves\"]} \\n'}))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T14:50:06.581538Z",
     "start_time": "2024-04-26T14:50:06.574593Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Load the csv file into a pandas DataFrame\n",
    "df = pd.read_csv('../examples/ttt_data.csv')\n",
    "csv_to_jsonl('../examples/ttt_data.csv', \"data.jsonl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T14:50:07.300996Z",
     "start_time": "2024-04-26T14:50:07.153181Z"
    }
   },
   "id": "1edd1a03ef45bb8d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f64fbf2b5cf64e2ca0281c3f5fd43bc5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files=\"data.jsonl\", split=\"train\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T14:50:09.122972Z",
     "start_time": "2024-04-26T14:50:08.476967Z"
    }
   },
   "id": "441317d100577027"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a tic-tac-toe solver. A tic-tac-toe board is a 3x3 grid. For example\n",
      "\n",
      "b,o,b\n",
      "x,b,b\n",
      "b,b,o\n",
      "\n",
      "b represents an empty position\n",
      "o represents a mark by player 1\n",
      "x represents a mark by player 2\n",
      "\n",
      "This state can also be represented in one line eg.\n",
      "bobxbbbbo\n",
      "\n",
      "The grid is also numbered where each number represents a position on the grid. eg.\n",
      "1,2,3\n",
      "4,5,6\n",
      "7,8,9\n",
      "\n",
      "a move can thus be represented by mark+number. Here are some examples:\n",
      "o5 means player 1 marks position 5 on the grid\n",
      "x1 means player 2 marks positoin 4 on the grid\n",
      "\n",
      "Your job is to generate the next best move given a tic-tac-toe board state.\n",
      "\n",
      "You must only answer with mark+number format and nothing else:\n",
      "o7\n",
      "\n",
      "\n",
      "Given the following state, what is the next best move?\n",
      "bbxxoobbb\n",
      "\n",
      "The next best move is\n"
     ]
    }
   ],
   "source": [
    "print(dataset[39]['prompt'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T15:00:16.644157Z",
     "start_time": "2024-04-26T15:00:16.638774Z"
    }
   },
   "id": "f5c9ca9acecb266a"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o3 \n"
     ]
    }
   ],
   "source": [
    "print(dataset[39]['completion'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T14:57:51.839732Z",
     "start_time": "2024-04-26T14:57:51.834729Z"
    }
   },
   "id": "cd6ce8380afbc570"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model_id = \"google/gemma-2b\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T14:50:11.460684Z",
     "start_time": "2024-04-26T14:50:11.453573Z"
    }
   },
   "id": "d6d4ab3efdae3169"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c476e2ddf7a45b2930e33c44d5a3138"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map='auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T18:44:53.367543Z",
     "start_time": "2024-04-25T18:44:46.837229Z"
    }
   },
   "id": "86d04c11d1ba8993"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=2,\n",
    "        #max_steps=30,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=500,\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"paged_adamw_8bit\"\n",
    "    ),\n",
    "    peft_config=lora_config,\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model(\"gemma-2b-sft\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-25T18:46:42.888716Z"
    }
   },
   "id": "86317d2f451a44e6"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ea970b0993b45d9bff79133a4d0a417"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heyandy/.conda/envs/RLProject/lib/python3.11/site-packages/transformers/generation/utils.py:1542: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>You are a tic-tac-toe solver. A tic-tac-toe board is a 3x3 grid. For example\n",
      "\n",
      "b,o,b\n",
      "x,b,b\n",
      "b,b,o\n",
      "\n",
      "b represents an empty position\n",
      "o represents a mark by player 1\n",
      "x represents a mark by player 2\n",
      "\n",
      "This state can also be represented in one line eg.\n",
      "bobxbbbbo\n",
      "\n",
      "The grid is also numbered where each number represents a position on the grid. eg.\n",
      "1,2,3\n",
      "4,5,6\n",
      "7,8,9\n",
      "\n",
      "a move can thus be represented by mark+number. Here are some examples:\n",
      "o5 means player 1 marks position 5 on the grid\n",
      "x1 means player 2 marks positoin 4 on the grid\n",
      "\n",
      "Your job is to generate the next best move given a tic-tac-toe board state.\n",
      "\n",
      "You must only answer with mark+number format and nothing else:\n",
      "o7\n",
      "\n",
      "\n",
      "Given the following state, what is the next best move?\n",
      "bbxxoobbb\n",
      "\n",
      "The next best move is\n",
      "o1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"gemma-2b-sft\", quantization_config=bnb_config, device_map='auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gemma-2b-sft\")\n",
    "\n",
    "inputs = tokenizer(dataset[39]['prompt'], return_tensors=\"pt\", return_attention_mask=False)\n",
    "outputs = model.generate(**inputs, max_new_tokens=4)\n",
    "\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "\n",
    "print(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T14:58:44.710506Z",
     "start_time": "2024-04-26T14:58:38.412650Z"
    }
   },
   "id": "56eaf3aee178cd86"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T18:45:22.124711Z",
     "start_time": "2024-04-25T18:45:22.122664Z"
    }
   },
   "id": "d6a5aa263ef379cc",
   "execution_count": 79
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
