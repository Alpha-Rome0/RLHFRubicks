{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbd3b53c28fb7674",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-24T22:44:12.897158100Z",
     "start_time": "2024-04-24T22:44:12.842954800Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import torch, csv, json\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "import bitsandbytes as bnb\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import LoraConfig\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T22:44:12.897158100Z",
     "start_time": "2024-04-24T22:44:12.893156200Z"
    }
   },
   "id": "14a2092c523f52c8"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def csv_to_jsonl(csv_path, jsonl_path):\n",
    "    with open('ttt_prompt.txt', 'r') as file:\n",
    "        # Read the entire file into a string\n",
    "        prompt = file.read()\n",
    "    with open(csv_path, 'r') as csv_file, open(jsonl_path, 'w') as jsonl_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        for row in reader:\n",
    "            jsonl_file.write(\n",
    "                json.dumps({\"prompt\": prompt.format(state = row[\"Game States\"]), \"completion\": f'{{\\n\\tnext_best_move: {row[\"Optimal Moves\"]}\\n}}'}) + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T22:44:12.897158100Z",
     "start_time": "2024-04-24T22:44:12.893156200Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Load the csv file into a pandas DataFrame\n",
    "df = pd.read_csv('../examples/ttt_data.csv')\n",
    "csv_to_jsonl('../examples/ttt_data.csv', \"data.jsonl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T22:44:12.967709900Z",
     "start_time": "2024-04-24T22:44:12.893156200Z"
    }
   },
   "id": "1edd1a03ef45bb8d"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f028d2894dae4febaa558f06dee1a4e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files=\"data.jsonl\", split=\"train\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T22:44:13.106638200Z",
     "start_time": "2024-04-24T22:44:12.949Z"
    }
   },
   "id": "441317d100577027"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a tic-tac-toe solver. A tic-tac-toe board is a 3x3 grid. For example\n",
      "\n",
      "b,o,b\n",
      "x,b,b\n",
      "b,b,o\n",
      "\n",
      "b represents an empty position\n",
      "o represents a mark by player 1\n",
      "x represents a mark by player 2\n",
      "\n",
      "This state can also be represented in one line eg.\n",
      "bobxbbbbo\n",
      "\n",
      "The grid is also numbered where each number represents a position on the grid. eg.\n",
      "1,2,3\n",
      "4,5,6\n",
      "7,8,9\n",
      "\n",
      "a move can thus be represented by mark+number. Here are some examples:\n",
      "o5 means player 1 marks position 5 on the grid\n",
      "x1 means player 2 marks positoin 4 on the grid\n",
      "\n",
      "Your job is to generate the next best move given a tic-tac-toe board state.\n",
      "\n",
      "Your output should be in the following json format:\n",
      "{\n",
      "    next_best_move: <move>\n",
      "}\n",
      "\n",
      "Given the following state, what is the next best move?\n",
      "bbbxoobox\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0]['prompt'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T22:44:13.156007800Z",
     "start_time": "2024-04-24T22:44:13.102639400Z"
    }
   },
   "id": "f5c9ca9acecb266a"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\tnext_best_move: x2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0]['completion'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T22:44:13.156007800Z",
     "start_time": "2024-04-24T22:44:13.152008600Z"
    }
   },
   "id": "cd6ce8380afbc570"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "\n",
    "LR = 1.41e-5\n",
    "BATCH_SIZE = 1\n",
    "MINI_BATCH_SIZE = 1\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    #bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model_id = \"google/gemma-2b-it\"\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "        r=16,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T22:44:13.156007800Z",
     "start_time": "2024-04-24T22:44:13.152008600Z"
    }
   },
   "id": "d6d4ab3efdae3169"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e0a849fa0ec4af59af24bf26d89f8da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T22:44:16.274548800Z",
     "start_time": "2024-04-24T22:44:13.152008600Z"
    }
   },
   "id": "86d04c11d1ba8993"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heyandy/venv/rlproject/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:246: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "514481448af04493933c071692a87701"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heyandy/venv/rlproject/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/peft/peft_model.py\", line 1129, in forward\n    return self.base_model(\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/peft/tuners/tuners_utils.py\", line 161, in forward\n    return self.model.forward(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/transformers/models/gemma/modeling_gemma.py\", line 1118, in forward\n    outputs = self.model(\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/transformers/models/gemma/modeling_gemma.py\", line 926, in forward\n    layer_outputs = decoder_layer(\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/transformers/models/gemma/modeling_gemma.py\", line 661, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/transformers/models/gemma/modeling_gemma.py\", line 189, in forward\n    return self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/bitsandbytes/nn/modules.py\", line 468, in forward\n    out = bnb.matmul_4bit(x, self.weight.t(), bias=bias, quant_state=self.weight.quant_state)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py\", line 579, in matmul_4bit\n    return MatMul4Bit.apply(A, B, out, bias, quant_state)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/autograd/function.py\", line 598, in apply\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py\", line 509, in forward\n    output = torch.nn.functional.linear(A, F.dequantize_4bit(B, quant_state).to(A.dtype).t(), bias)\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU \n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 7\u001B[0m\n\u001B[1;32m      1\u001B[0m trainer \u001B[38;5;241m=\u001B[39m SFTTrainer(\n\u001B[1;32m      2\u001B[0m     model,\n\u001B[1;32m      3\u001B[0m     train_dataset\u001B[38;5;241m=\u001B[39mdataset,\n\u001B[1;32m      4\u001B[0m     packing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m      5\u001B[0m     peft_config\u001B[38;5;241m=\u001B[39mlora_config\n\u001B[1;32m      6\u001B[0m )\n\u001B[0;32m----> 7\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m trainer\u001B[38;5;241m.\u001B[39msave_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgemma-2b-it-sft\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/venv/rlproject/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:361\u001B[0m, in \u001B[0;36mSFTTrainer.train\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    358\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mneftune_noise_alpha \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_trainer_supports_neftune:\n\u001B[1;32m    359\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_trl_activate_neftune(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel)\n\u001B[0;32m--> 361\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    363\u001B[0m \u001B[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001B[39;00m\n\u001B[1;32m    364\u001B[0m \u001B[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001B[39;00m\n\u001B[1;32m    365\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mneftune_noise_alpha \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_trainer_supports_neftune:\n",
      "File \u001B[0;32m~/venv/rlproject/lib/python3.8/site-packages/transformers/trainer.py:1859\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1857\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   1858\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1859\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1860\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1861\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1862\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1863\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1864\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/rlproject/lib/python3.8/site-packages/transformers/trainer.py:2203\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2200\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_begin(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[1;32m   2202\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39maccumulate(model):\n\u001B[0;32m-> 2203\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2205\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   2206\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[1;32m   2207\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[1;32m   2208\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[1;32m   2209\u001B[0m ):\n\u001B[1;32m   2210\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[1;32m   2211\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[0;32m~/venv/rlproject/lib/python3.8/site-packages/transformers/trainer.py:3138\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[0;34m(self, model, inputs)\u001B[0m\n\u001B[1;32m   3135\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_mb\u001B[38;5;241m.\u001B[39mreduce_mean()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m   3137\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_context_manager():\n\u001B[0;32m-> 3138\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mn_gpu \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3141\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mmean()  \u001B[38;5;66;03m# mean() to average on multi-gpu parallel training\u001B[39;00m\n",
      "File \u001B[0;32m~/venv/rlproject/lib/python3.8/site-packages/transformers/trainer.py:3161\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[0;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[1;32m   3159\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3160\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 3161\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3162\u001B[0m \u001B[38;5;66;03m# Save past state if it exists\u001B[39;00m\n\u001B[1;32m   3163\u001B[0m \u001B[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001B[39;00m\n\u001B[1;32m   3164\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mpast_index \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/venv/rlproject/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:185\u001B[0m, in \u001B[0;36mDataParallel.forward\u001B[0;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodule(\u001B[38;5;241m*\u001B[39minputs[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodule_kwargs[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m    184\u001B[0m replicas \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreplicate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodule, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice_ids[:\u001B[38;5;28mlen\u001B[39m(inputs)])\n\u001B[0;32m--> 185\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparallel_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreplicas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodule_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgather(outputs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_device)\n",
      "File \u001B[0;32m~/venv/rlproject/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:200\u001B[0m, in \u001B[0;36mDataParallel.parallel_apply\u001B[0;34m(self, replicas, inputs, kwargs)\u001B[0m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparallel_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[Any]:\n\u001B[0;32m--> 200\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparallel_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreplicas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_ids\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mreplicas\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/rlproject/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py:108\u001B[0m, in \u001B[0;36mparallel_apply\u001B[0;34m(modules, inputs, kwargs_tup, devices)\u001B[0m\n\u001B[1;32m    106\u001B[0m     output \u001B[38;5;241m=\u001B[39m results[i]\n\u001B[1;32m    107\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, ExceptionWrapper):\n\u001B[0;32m--> 108\u001B[0m         \u001B[43moutput\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    109\u001B[0m     outputs\u001B[38;5;241m.\u001B[39mappend(output)\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m~/venv/rlproject/lib/python3.8/site-packages/torch/_utils.py:705\u001B[0m, in \u001B[0;36mExceptionWrapper.reraise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    701\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    702\u001B[0m     \u001B[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001B[39;00m\n\u001B[1;32m    703\u001B[0m     \u001B[38;5;66;03m# instantiate since we don't know how to\u001B[39;00m\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 705\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/peft/peft_model.py\", line 1129, in forward\n    return self.base_model(\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/peft/tuners/tuners_utils.py\", line 161, in forward\n    return self.model.forward(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/transformers/models/gemma/modeling_gemma.py\", line 1118, in forward\n    outputs = self.model(\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/transformers/models/gemma/modeling_gemma.py\", line 926, in forward\n    layer_outputs = decoder_layer(\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/transformers/models/gemma/modeling_gemma.py\", line 661, in forward\n    hidden_states = self.mlp(hidden_states)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/transformers/models/gemma/modeling_gemma.py\", line 189, in forward\n    return self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/bitsandbytes/nn/modules.py\", line 468, in forward\n    out = bnb.matmul_4bit(x, self.weight.t(), bias=bias, quant_state=self.weight.quant_state)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py\", line 579, in matmul_4bit\n    return MatMul4Bit.apply(A, B, out, bias, quant_state)\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/torch/autograd/function.py\", line 598, in apply\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\n  File \"/home/heyandy/venv/rlproject/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py\", line 509, in forward\n    output = torch.nn.functional.linear(A, F.dequantize_4bit(B, quant_state).to(A.dtype).t(), bias)\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU \n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=dataset,\n",
    "    packing=True,\n",
    "    peft_config=lora_config\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_pretrained(\"gemma-2b-it-sft\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T22:44:21.158330200Z",
     "start_time": "2024-04-24T22:44:16.277450200Z"
    }
   },
   "id": "86317d2f451a44e6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T22:44:21.158330200Z"
    }
   },
   "id": "56eaf3aee178cd86"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
